{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ROOT import (TCanvas, TPad, TFile, TPaveLabel, \n",
    "                  TPaveText, gROOT, TH1F, TH1D, TLegend, \n",
    "                  gStyle, TH2F, TChain, TGraphErrors, TText, gPad, gROOT, TTree)\n",
    "from array import array\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "        \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate, SimpleRNN, GRU, Masking, Lambda, Reshape, Dropout, RNN\n",
    "from keras.optimizers import Adagrad, SGD, RMSprop, Adam\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LeakyReLU, LSTM, Conv1D, SimpleRNN, Concatenate\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import keras.backend as K\n",
    "import pickle\n",
    "#import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import datetime, os\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have 23 features\n",
      "mZp is MZ1\n"
     ]
    }
   ],
   "source": [
    "# all methods here\n",
    "def clean_arrays(data, weights=None):\n",
    "    new = []\n",
    "    for d in data:\n",
    "        #if all(di == 0. for di in d):\n",
    "        if d[-1]==0.:\n",
    "            continue\n",
    "        new.append(d)\n",
    "    out = np.array(new)\n",
    "    print(\"before\", data.shape, 'after', out.shape)\n",
    "    return out\n",
    "\n",
    "def build_array(fname, trname, features, cuts, mll_idx = 10, should_clean_arrays=True, **kwargs):\n",
    "    #print(features[mll_idx])\n",
    "    f = TFile.Open(fname)\n",
    "    tree = f.Get(trname)\n",
    "    n_events = tree.GetEntries()\n",
    "    data = np.zeros((n_events, len(features)))\n",
    "    for n, (event, element) in enumerate(zip(tree, data)):\n",
    "        for i, feature in enumerate(features):\n",
    "            try:\n",
    "                val = getattr(event, feature)\n",
    "            except:\n",
    "                val = None\n",
    "            if feature in cuts and eval(\"{}{}\".format(val, cuts[feature])):\n",
    "                element[i] = getattr(event, feature)\n",
    "            elif feature in cuts:\n",
    "                element = np.zeros(len(features))\n",
    "                break\n",
    "            elif feature == 'train_mass':\n",
    "                element[i] = getattr(event, features[mll_idx])\n",
    "            elif feature == 'MZ1_MZ2':\n",
    "                element[i] = getattr(event, 'MZ1')-getattr(event, 'MZ2')\n",
    "            else:\n",
    "                element[i] = val\n",
    "    return clean_arrays(data) if should_clean_arrays else data\n",
    "\n",
    "features = ('train_mass', ## 0\n",
    "            'PtL1',       ## 1\n",
    "            'PtL2',       ## 2\n",
    "            'PtL3',       ## 3\n",
    "            'PtL4',       ## 4\n",
    "            'EtaL1',      ## 5\n",
    "            'EtaL2',      ## 6\n",
    "            'EtaL3',      ## 7\n",
    "            'EtaL4',      ## 8\n",
    "            'MZ1',        ## 9\n",
    "            'MZ2',        ## 10\n",
    "            'MZ1_MZ2',    ## 11\n",
    "            'PtZ1',       ## 12\n",
    "            'PtZ2',       ## 13\n",
    "            'MZZ',        ## 14\n",
    "            'PtZZ',       ## 15\n",
    "            'DeltaRl12',  ## 16\n",
    "            'DeltaRl34',  ## 17\n",
    "            'dEtal12',    ## 18\n",
    "            'dEtal34',    ## 19\n",
    "            'run',        ## 20\n",
    "            'event',      ## 21\n",
    "            'weight')     ## 22\n",
    "\n",
    "# these are your cuts that preselect events, empty now\n",
    "cuts = dict()\n",
    "#cuts = {\"MZZ\": \"<120\"}\n",
    "\n",
    "mll_idx = 9 # 10 when signal sample < 40GeV; 9 when signal >40GeV\n",
    "print(\"have {} features\".format(len(features)))\n",
    "print(\"mZp is\", features[mll_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASS_FEATURE_INDEX = 0\n",
    "def prep_mass(xbtrain, xstrain, norm=None):\n",
    "    np.random.seed(42)\n",
    "    new = xbtrain.copy()\n",
    "    sump = sum(xstrain[:,-1])\n",
    "    for d in new:\n",
    "        mass = np.random.choice(xstrain[:,MASS_FEATURE_INDEX], p=1/sump*xstrain[:,-1])\n",
    "        if norm:\n",
    "            mass = mass / norm\n",
    "        d[MASS_FEATURE_INDEX] = mass\n",
    "    return new\n",
    "\n",
    "def get_part_feature(xtrain):\n",
    "    #nf = [0,1,2,3,4,5,6,7,8,11,12,13,14,15,16,17,18,19]\n",
    "    nf = [0,1,2,3,4,5,6,7,8,11,12,13,14,16,17,18,19]\n",
    "    xtrain = xtrain[:,nf]\n",
    "    return xtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For signal trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at file: /Users/zhuheling/ML/keras/example_hep/myTest/data/tree_fake.root\n",
      "Read tree: tree_NOMINAL Entries: 40855\n",
      "[[   96.68231711    69.47304687    32.69924219 ... -9999.\n",
      "  -9999.         -9999.        ]\n",
      " [   85.5777831     29.33117578    24.99976562 ... -9999.\n",
      "  -9999.         -9999.        ]\n",
      " [   35.86128791    94.44622656    22.36219922 ... -9999.\n",
      "  -9999.         -9999.        ]\n",
      " ...\n",
      " [   68.36365433    37.92746875    31.70921289 ... -9999.\n",
      "  -9999.         -9999.        ]\n",
      " [   52.04980381    34.13291797    23.31287109 ... -9999.\n",
      "  -9999.         -9999.        ]\n",
      " [   69.61498517    28.49956836    14.81537695 ... -9999.\n",
      "  -9999.         -9999.        ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model_hM = load_model(\"Below180/models/noptZZ_17f_hM.h5\")\n",
    "#model_lM = load_model(\"Below180/models/Below120_18features_lM.h5\")\n",
    "\n",
    "#msamp = [42,45,48,51,54,57,60,63,66,69,72,75]\n",
    "#msamp = ['qqZZ', 'ggZZ', 'ggZZ_low', 'fake']\n",
    "msamp = ['fake']\n",
    "\n",
    "base = '/Users/zhuheling/ML/keras/example_hep/myTest/'\n",
    "for mass in msamp:\n",
    "    _file = base+'data/tree_{}.root'.format(mass)\n",
    "    print(\"Looking at file:\", _file)\n",
    "    f = TFile.Open(_file)\n",
    "    list_tree=f.GetListOfKeys()\n",
    "    #for it,trname in enumerate(trlist):\n",
    "    for key in list_tree:\n",
    "        tree=key.ReadObj()\n",
    "        trname=tree.GetName()\n",
    "        if \"tree_\" not in trname: continue\n",
    "        print (\"Read tree:\", trname, \"Entries:\", tree.GetEntries())\n",
    "        dat = build_array(_file, trname, features, cuts, mll_idx = 9, should_clean_arrays=False)\n",
    "        dat1 = dat\n",
    "        dat1[:,0] = dat1[:,9]\n",
    "        dat1_par = get_part_feature(dat1)\n",
    "        print(dat1_par)\n",
    "        pred_hM = model_hM.predict(dat1_par).ravel()   \n",
    "    \n",
    "        #dat2 = dat\n",
    "        #dat2[:,0] = dat2[:,10]\n",
    "        #dat2_par = get_part_feature(dat2)\n",
    "        #pred_lM = model_lM.predict(dat2_par).ravel()  \n",
    " \n",
    "        ## plot output score\n",
    "        #plt.hist(pred_hM, bins=50, histtype='step', label='signal MZ1', density=True)\n",
    "        #plt.hist(pred_lM, bins=50, histtype='step', label='signal MZ2', density=True)\n",
    "        #plt.legend(loc=2)\n",
    "        #plt.xlabel(\"Output score\")\n",
    "        #plt.ylabel(\"Events\")\n",
    "        #plt.show()\n",
    "\n",
    "        new_basename = os.path.basename(_file.replace('.root', '_dnn.root'))\n",
    "        tree = f.Get(trname)\n",
    "        \n",
    "        newfile = TFile('{}/DNNtree/{}'.format(base, new_basename),'UPDATE')    \n",
    "        newtree = tree.CloneTree()\n",
    "        newtree.SetName(trname)\n",
    "    \n",
    "        DNN_highM = array( 'f', [ 0. ] )\n",
    "        newbranch_0 = newtree.Branch( 'DNN_highM', DNN_highM, 'DNN_highM/F' )    \n",
    "        #DNN_lowM = array( 'f', [ 0. ] )\n",
    "        #newbranch_1 = newtree.Branch( 'DNN_lowM', DNN_lowM, 'DNN_lowM/F' )   \n",
    "        \n",
    "        for i, preds in enumerate(pred_hM):\n",
    "            DNN_highM[0] = preds\n",
    "            #DNN_lowM[0] = preds[1]\n",
    "            newbranch_0.Fill()\n",
    "            #newbranch_1.Fill()\n",
    "\n",
    "        newtree.Write()\n",
    "        newfile.Close()\n",
    "\n",
    "    f.Close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
